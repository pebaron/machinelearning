# -*- coding: utf-8 -*-
"""plot_digits_classif.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/marcinwolter/MachineLearning2020/blob/main/plot_digits_classif.ipynb
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

"""Simple visualization and classification of the digits dataset
=============================================================

Plot the first few samples of the digits dataset and a 2D representation
built using PCA, then do a simple classification
"""

from sklearn.datasets import load_digits
digits = load_digits()

"""Plot the data: images of digits
-------------------------------

Each event is an 8x8 image
"""

from matplotlib import pyplot as plt
fig = plt.figure(figsize=(10, 10))  # figure size in inches 10 by 10 plots = 100
fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)

for i in range(100):
    ax = fig.add_subplot(10, 10, i + 1, xticks=[], yticks=[])
    ax.imshow(digits.images[i], cmap=plt.cm.binary, interpolation='nearest')
    # label the image with the target value
    ax.text(0, 7, str(digits.target[i]))

"""Plot a projection on the 2 first principal axis
------------------------------------------------
"""

plt.figure()

#print(digits.data)

from sklearn.decomposition import PCA
#pca = PCA(n_components=3)
pca = PCA(n_components=2)
proj = pca.fit_transform(digits.data)
print(proj.shape)
#fig = plt.figure()
#ax = fig.add_subplot(111, projection='3d')
plt.scatter(proj[:, 0], proj[:, 1], c=digits.target.astype(int), cmap=plt.get_cmap('Paired', 10), vmin=-0.5, vmax=9.5)
#ax.scatter(proj[:, 0], proj[:, 1], proj[:, 2], c=digits.target.astype(int), cmap=plt.get_cmap('Paired', 10), vmin=-0.5, vmax=9.5)
#plt.show()
#plt.colorbar()

"""# **Plot principal components**"""

pca = PCA(n_components=64)

proj = pca.fit_transform(digits.data)

principal = pca.explained_variance_
print(pca.explained_variance_)

fig, ax = plt.subplots(tight_layout=True)
ax.bar( [x for x in range(principal.size)], principal)

"""Quantify the performance"""

import numpy as np
from sklearn.model_selection import train_test_split

# split the data into training and validation sets
init = np.random.randint(0,1000)
X_train, X_test, y_train, y_test = train_test_split(pca.fit_transform(digits.data)[:,0:20], digits.target, random_state=init) 
# 32 eigen vectors out of 64, 

"""## **Classify with Naive Bayes Classifies / Fisher Linear Discriminants**"""

from sklearn.naive_bayes import GaussianNB # with 32 eigenvectors
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis


# train the model, choose the classifier, gaus naive bayes vs. Fisher discriminant
clf = GaussianNB()
#clf = LinearDiscriminantAnalysis()


print(clf.fit(X_train, y_train))
#print(clf.feature_importances_)  

# use the model to predict the labels of the test data
predicted = clf.predict(X_test)
expected = y_test


print("Score = ",clf.score(X_train, y_train))

# Plot the prediction
fig = plt.figure(figsize=(6, 6))  # figure size in inches
fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)

# split the data into training and validation sets
XP_train, XP_test, yP_train, yP_test = train_test_split(digits.data, digits.target, random_state=init)
# plot the digits: each image is 8x8 pixels
for i in range(64):
    ax = fig.add_subplot(8, 8, i + 1, xticks=[], yticks=[])
    ax.imshow(XP_test.reshape(-1, 8, 8)[i], cmap=plt.cm.binary,
              interpolation='nearest')

    # label the image with the target value
    if predicted[i] == expected[i]:
        ax.text(0, 7, str(expected[i])+" "+str(predicted[i]), color='green')
    else:
        ax.text(0, 7, str(expected[i])+" "+str(predicted[i]), color='red')

"""In the plot above first label is the expected (true) digit, second the reconstructed digit

Number of matches
"""

matches = (predicted == expected)
print(matches.sum())

"""The total number of data points"""

print(len(matches))

"""And now, the ratio of correct predictions"""

matches.sum() / float(len(matches))

"""Print the classification report"""

from sklearn import metrics
print(metrics.classification_report(expected, predicted))

"""# **Print the confusion matrix (expected true label vs. the reconstructed label)**"""

print(metrics.confusion_matrix(expected, predicted))

plt.show()