# -*- coding: utf-8 -*-
"""EnsambleLearningExample.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/marcinwolter/MachineLearning2020/blob/main/EnsambleLearningExample.ipynb
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_gaussian_quantiles

from sklearn.neighbors import KNeighborsClassifier
#from sklearn.svm import SVC
from sklearn.gaussian_process import GaussianProcessClassifier
from sklearn.gaussian_process.kernels import RBF
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

from sklearn.model_selection import train_test_split

from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
 
# Construct dataset
X1, y1 = make_gaussian_quantiles(cov=2.,
                                 n_samples=8000, n_features=2,
                                 n_classes=2, random_state=1)
X2, y2 = make_gaussian_quantiles(mean=(3, 3), cov=1.5,
                                 n_samples=12000, n_features=2,
                                 n_classes=2, random_state=1)
X = np.concatenate((X1, X2))
y = np.concatenate((y1, - y2 + 1))


# Split data into train and test subsets
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.5, shuffle=True)




 
# Create and fit a classifier
clf = DecisionTreeClassifier(max_depth=5)
#clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),n_estimators=6000)
#clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=5),n_estimators=600)
#clf = BaggingClassifier(DecisionTreeClassifier(max_depth=10),n_estimators=100)

#clf = GaussianNB()
#clf = AdaBoostClassifier(learning_rate=2.5,base_estimator=GaussianNB(),n_estimators=800,algorithm='SAMME.R') #,algorithm='SAMME.R')
#clf = BaggingClassifier(GaussianNB(),max_samples=0.009,n_estimators=500)

#clf = KNeighborsClassifier(n_neighbors=1)
#clf = BaggingClassifier(KNeighborsClassifier(n_neighbors=1),n_estimators=500)


#clf = LinearDiscriminantAnalysis()
#clf = BaggingClassifier(LinearDiscriminantAnalysis(),max_samples=0.009,n_estimators=10000)

#clf = GradientBoostingClassifier(learning_rate=0.1,n_estimators=200)
#clf = RandomForestClassifier(n_estimators=200)

# Takes extremaly long time
#clf = GaussianProcessClassifier(1.0 * RBF(1.0))
#clf = BaggingClassifier(GaussianProcessClassifier(1.0 * RBF(1.0)))

clf.fit(X_train, y_train)

plot_colors = "br"
plot_step = 0.1
class_names = "AB"
 
plt.figure(figsize=(10, 5))
 
# Plot the decision boundaries
x_min, x_max = X_test[:, 0].min() - 1, X_test[:, 0].max() + 1
y_min, y_max = X_test[:, 1].min() - 1, X_test[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),
                     np.arange(y_min, y_max, plot_step))
 
Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)
cs = plt.contourf(xx, yy, Z, cmap=plt.cm.Paired)
plt.axis("tight")
 
# Plot the test points
print("Plotting the test points")
for i, n, c in zip(range(2), class_names, plot_colors):
    # plot first 400 test data points
    N = min(400,len(y_test))
    idx = np.where(y_test[0:N] == i)
    print("Plotting ",len(idx)," datapoints.")
    plt.scatter(X_test[idx, 0], X_test[idx, 1],
                c=c, cmap=plt.cm.Paired,
                label="Class %s" % n)
plt.xlim(x_min, x_max)
plt.ylim(y_min, y_max)
plt.legend(loc='upper right')
plt.xlabel('x')
plt.ylabel('y')
plt.title('Decision Boundary')

# plot the roc curve
figure = plt.figure(figsize=(10, 5))
ZZ = clf.predict_proba(X_test)[:, 1]
#print(y_test.shape,"   ",Z.shape)
fpr, tpr, _ = roc_curve(y_test, ZZ)
plt.plot(fpr, tpr, label="ROC")
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
#plt.title('ROC curve')
plt.legend(loc='best')
auc = roc_auc_score(y_test, ZZ)
plt.text(0.7, 0.5, ('AUC = %.2f' % auc),
        size=15, horizontalalignment='right')

plt.show()